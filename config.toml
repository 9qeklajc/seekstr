# Seekstr Configuration File
# Copy this file to config.toml and customize as needed

[backend]
# Backend type: "openai", "whisper", or "auto"
# - "openai": Use OpenAI API for transcription/description
# - "whisper": Use local Whisper model
# - "auto": Automatically choose based on available credentials
type = "auto"

# OpenAI API key (required if type is "openai" or "auto")
# openai_api_key = "sk-..."

# Path to Whisper model file (required if type is "whisper" or "auto")
whisper_model_path = "/home/k0/.cache/whisper/ggml-large-v3.bin"

[relays]
# Source relays to listen for Nostr events
sources = [
    "wss://relay.damus.io",
    "wss://nos.lol",
    "wss://relay.nostr.band"
]

# Sink relays to publish processed results
sinks = [
    "wss://seekstr.otrta.me",
]

# Optional: Event filters for incoming events
[[relays.filters]]
# Filter for kind 1 (text notes) events only
kinds = [1]

[processing]
# State file to track processed events
state_file = "seekstr_state.json"

# Optional: Batch size for processing multiple URLs
# batch_size = 5

# Optional: Timeout for processing in seconds
timeout_seconds = 30

[logging]
# Log level: "trace", "debug", "info", "warn", "error"
level = "info"

# Optional: Specific modules to configure logging for
modules = ["seekstr", "eventflow", "scribe"]